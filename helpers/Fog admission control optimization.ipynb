{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required packages:\n",
    "\n",
    " + numpy\n",
    " + scipy\n",
    " + openopt: `pip install OpenOpt DerApproximator FuncDesigner`\n",
    " + nlopt: https://nlopt.readthedocs.io/en/latest/NLopt_Installation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "from scipy.optimize import fsolve, brentq\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from IPython.display import display, Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary setup\n",
    "\n",
    "First, let's input the parameters of the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application\n",
    "R_exp = 7\n",
    "R=10**R_exp\n",
    "x_comp = 1. * (10**7) #CPU Cycles\n",
    "s_raw = 1.* (10**6) #B\n",
    "s_proc = 1. *(10**4)#B\n",
    "delta_app = 0.091 #s\n",
    "kappa = 0.\n",
    "\n",
    "##Zipf\n",
    "alpha = 1.0\n",
    "\n",
    "#Fog\n",
    "s_cachef_B = 10.0**9 #10.**8 #B\n",
    "C_compf = 3. * (10**9) #Hz\n",
    "C_acc = (10./8) *10**9 #Bps\n",
    "tau_acc = 4. * (10**(-3)) #s\n",
    "\n",
    "#Cloud\n",
    "C_compc = 2.*(10**9) #Hz\n",
    "tau_DB = 1. * (10**(-3)) #s\n",
    "C_core  = (1./8) * (10**9) #Bps\n",
    "tau_core = 40. * (10**(-3)) #s\n",
    "\n",
    "tau_TLSc = tau_core + tau_acc\n",
    "tau_TLSf = tau_acc\n",
    "\n",
    "p_n = 0.08 / (10**9) #$/B/h\n",
    "p_c = 0.033174 #$/2GHz CPU/h\n",
    "p_s = 0.004446 / (10**9) #$/B/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the next cell to precompute the items popularity and define helper functions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.arange(1,R+1)**(-alpha)\n",
    "pop /= np.sum(pop)\n",
    "\n",
    "s_cache_f = s_cachef_B / s_proc\n",
    "def s_cache_c (s_cachec_B): return s_cachec_B / sproc\n",
    "\n",
    "def che_prob(tc, item_pop): return 1 - np.exp(-item_pop*tc)\n",
    "\n",
    "def tc_func(C,pop): return fsolve(lambda t: C - np.sum(che_prob(t,pop)), C)[0]\n",
    "\n",
    "def expected_latency_mg1ps (capacity, arr_rate, job_size=1):\n",
    "    job_completion_rate = capacity / job_size\n",
    "    if arr_rate > job_completion_rate:\n",
    "        return np.inf\n",
    "    return (1 / job_completion_rate) / (1 - (arr_rate / job_completion_rate))\n",
    "\n",
    "def variance_latency_mm1ps (capacity, arrival_rate, job_size=1):\n",
    "    job_completion_rate = capacity / job_size\n",
    "    #if arr_rate > job_completion_rate:\n",
    "    #    return np.inf\n",
    "    lambda_mu = arrival_rate / job_completion_rate \n",
    "    denominator = (1/job_completion_rate)**2 * (2+lambda_mu)\n",
    "    numerator = (1-lambda_mu)**2 * (2-lambda_mu)\n",
    "    return denominator / numerator\n",
    "\n",
    "def expected_queue_size_mg1ps (capacity, arrival_rate, job_size=1):\n",
    "    job_completion_rate = capacity/job_size\n",
    "    rho = arrival_rate/job_completion_rate\n",
    "    return rho / (1 - rho)\n",
    "\n",
    "def expected_queue_size_mginf(capacity, arrival_rate, job_size = 1):\n",
    "    return arrival_rate / (capacity/job_size)\n",
    "\n",
    "def variance_exp(parameter):\n",
    "    return 1 / (parameter*parameter)\n",
    "\n",
    "def variance_mginf (capacity, job_size=1):\n",
    "    return variance_exp(capacity/job_size)\n",
    "\n",
    "def capacity_ccloud (arrival_rate, job_size=1):\n",
    "    return arrival_rate * job_size / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding $\\phi$, $k_{LFU}$, and $k_{LRU}$\n",
    "\n",
    "## The Fog-offload model\n",
    "\n",
    "First let's create functions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_rate_fog (phi,arr_rate,pop): return phi*pop*arr_rate\n",
    "def arr_rate_fog_miss (phi, arr_rate, hit_fog, pop): return phi*pop*(1-hit_fog)*arr_rate\n",
    "def arr_rate_cloud (phi, arr_rate, pop): return (1-phi)*pop*arr_rate\n",
    "def arr_rate_cloud_miss (phi, arr_rate, hit_cloud, pop): return (1-phi)*pop*(1-hit_cloud)*arr_rate\n",
    "\n",
    "def expected_response_time (arr_rate, phi, s_cachec, hit_fog, hit_cloud):\n",
    "    \n",
    "    # CLOUD\n",
    "    lambda_c = np.sum(arr_rate_cloud(phi, arr_rate, pop))\n",
    "\n",
    "    l_cloud_m = tau_DB + (x_comp / C_compc)\n",
    "    l_cloud = tau_TLSc + expected_latency_mg1ps(C_core, lambda_c, s_proc) + tau_core \\\n",
    "            + np.sum((1-hit_cloud)*pop*(1-phi))*l_cloud_m\n",
    "\n",
    "    # FOG\n",
    "    arr_rate_fog_m = np.sum(arr_rate_fog_miss(phi, arr_rate, hit_fog, pop))\n",
    "\n",
    "    l_fog_m = tau_TLSf + expected_latency_mg1ps(C_acc, arr_rate_fog_m, s_raw) + tau_acc + \\\n",
    "            expected_latency_mg1ps(C_compf, arr_rate_fog_m, x_comp)\n",
    "    l_fog = tau_TLSf + np.sum((1-hit_fog)*pop*phi) * l_fog_m\n",
    "    \n",
    "    #display(Math(r\"\\lambda_{{f,m}} = {:2.2f},\\, \\mathbf E[T_{{f,m}}] = {:2.3f}\".format(arr_rate_fog_m, l_fog_m)))\n",
    "    \n",
    "    # ALL\n",
    "    l_acc = expected_latency_mg1ps(C_acc, arr_rate, s_proc) + tau_acc\n",
    "    \n",
    "    #display(Math(r\"\\mathbf E[T_f] = {:2.3f},\\, \\mathbf E[T_c] = {:2.3f},\\, \\mathbf E[T_{{acc}}]={:2.3f}\".format(l_fog, l_cloud, l_acc)))\n",
    "\n",
    "    ret = l_acc + np.sum(pop*phi)*l_fog + np.sum(pop*(1-phi))*l_cloud\n",
    "    #display(Math(r\"\\mathbf E[T] = {:2.3f}\".format(ret)))\n",
    "    return l_acc + np.sum(pop*phi)*l_fog + np.sum(pop*(1-phi))*l_cloud\n",
    "\n",
    "def stddev_response_time (arr, phi, s_cachec, hit_fog, hit_cloud):\n",
    "    # CLOUD\n",
    "    lambda_c = np.sum(arr_rate_cloud(phi, arr_rate, pop))\n",
    "\n",
    "    v_cloud_m = variance_mginf (C_compc, x_comp)\n",
    "    v_cloud = np.sum((1-hit_cloud)*pop*(1-phi)) * v_cloud_m + variance_latency_mm1ps(C_acc, arr_rate, s_proc)\n",
    "    \n",
    "    # FOG\n",
    "    arr_rate_fog_m = np.sum(arr_rate_fog_miss(phi, arr_rate, hit_fog, pop))\n",
    "\n",
    "    v_fog_m = variance_latency_mm1ps(C_acc, arr_rate_fog_m, s_raw) + \\\n",
    "            variance_latency_mm1ps(C_compf, arr_rate_fog_m, x_comp)\n",
    "    v_fog = np.sum((1-hit_fog)*pop*phi) * v_fog_m\n",
    "    \n",
    "    # ALL\n",
    "    v_acc = variance_latency_mm1ps(C_acc, arr, s_proc) + tau_acc\n",
    "\n",
    "    return np.sqrt(v_acc + np.sum(pop*phi)*v_fog + np.sum(pop*(1-phi))*v_cloud)\n",
    "\n",
    "def cost_network (arr_rate, phi, pop):\n",
    "    return p_n * s_proc * np.sum(arr_rate_cloud(phi, arr_rate, pop)) * 3600 #To get the hourly cost\n",
    "\n",
    "def cost_compute(arr_rate, phi, pop, hit_cloud):\n",
    "    return p_c * expected_queue_size_mginf(C_compc, np.sum(arr_rate_cloud_miss(phi, arr_rate, hit_cloud, pop)), x_comp)\n",
    "\n",
    "def cost_memory(s_cachec):\n",
    "    return s_cachec * s_proc * p_s\n",
    "\n",
    "def cost (arr_rate, phi, pop, hit_cloud, s_cachec):\n",
    "    return cost_network(arr_rate, phi, pop) + cost_compute(arr_rate, phi, pop, hit_cloud) + cost_memory(s_cachec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical resolution\n",
    "\n",
    "Now let's solve the system for a given $\\lambda$ by setting the `arr_rate` variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_rate = 1e4\n",
    "\n",
    "def cost_func(arr_rate, phi, pop, s_cachec):\n",
    "    tc_cloud = tc_func(s_cachec, pop*(1-phi))\n",
    "    hit_cloud = che_prob(tc_cloud, pop*(1-phi))\n",
    "    return cost(arr_rate, phi, pop, hit_cloud, s_cachec)\n",
    "\n",
    "def constraint_func(arr_rate, phi, s_cachec, kappa, delta, hit_fog=None):\n",
    "    \n",
    "    tc_cloud = tc_func(s_cachec, pop*(1-phi))\n",
    "    hit_cloud = che_prob(tc_cloud, pop*(1-phi))\n",
    "    if hit_fog is None:\n",
    "        tc_fog = tc_func(s_cache_f, pop*phi)\n",
    "        hit_fog = che_prob(tc_fog, pop*phi)\n",
    "    \n",
    "    exp = expected_response_time (arr_rate, phi, s_cachec, hit_fog, hit_cloud)\n",
    "    stddev = stddev_response_time (arr_rate, phi, s_cachec, hit_fog, hit_cloud)\n",
    "    ret = exp+kappa*stddev\n",
    "    #display(Math(\"{:2.3f}={:2.3f}+{}\\cdot {:2.3f}\".format(ret, exp, kappa, stddev)))\n",
    "    \n",
    "    return ret-delta\n",
    "\n",
    "\n",
    "### Blind\n",
    "def blind_cost_func(point, arr_rate, pop, *args, **kwargs):\n",
    "    phi_B,s_cachec = point\n",
    "    phi = np.zeros(R)+phi_B\n",
    "    \n",
    "    return cost_func(arr_rate, phi, pop, s_cachec)\n",
    "\n",
    "def blind_constraint_func(point, arr_rate, pop, kappa, delta, hit_fog, *args, **kwargs):\n",
    "    phi_B,s_cachec = point\n",
    "    phi = np.zeros(R)+phi_B\n",
    "    \n",
    "    return constraint_func(arr_rate, phi, s_cachec, kappa, delta, hit_fog)\n",
    "\n",
    "### LFU\n",
    "def lfu_cost_func(point, arr_rate, pop, *args, **kwargs):\n",
    "    klfu,s_cachec = point\n",
    "    phi = np.zeros(R)\n",
    "    fklfu = int(klfu)\n",
    "    phi[np.arange(0,fklfu)] = 1\n",
    "    if fklfu != R:\n",
    "        phi[fklfu] = klfu-fklfu\n",
    "    \n",
    "    return cost_func(arr_rate, phi, pop, s_cachec)\n",
    "    \n",
    "def lfu_constraint_func(point, arr_rate, pop, kappa, delta, *args, **kwargs):\n",
    "    klfu,s_cachec = point\n",
    "    phi = np.zeros(R)\n",
    "    fklfu = int(klfu)\n",
    "    phi[np.arange(0,fklfu)] = 1\n",
    "    if fklfu != R:\n",
    "        phi[fklfu] = klfu-fklfu\n",
    "    \n",
    "    return constraint_func(arr_rate, phi, s_cachec, kappa, delta)\n",
    "\n",
    "    \n",
    "### LRU\n",
    "###### DTMC\n",
    "def qa(t1,t2,pop): return 1. - np.exp(-t1*pop)\n",
    "def qb(t1,t2,pop): return np.exp(-t2*pop)\n",
    "\n",
    "def p11(t1,t2,pop): return qa(t1,t2,pop)**2 / (qa(t1,t2,pop) + qb(t1,t2,pop))\n",
    "def p01(t1,t2,pop): return qa(t1,t2,pop)*(1./(qa(t1,t2,pop)+qb(t1,t2,pop)) -1.)\n",
    "def p01p11(t1,t2,pop): return p11(t1,t2,pop)+p01(t1,t2,pop)\n",
    "\n",
    "###### Cost/constraint functions\n",
    "def lru_cost_func(point, arr_rate, pop, *args, **kwargs):\n",
    "    klru,s_cachec = point\n",
    "    tc_filter = tc_func(klru,pop)\n",
    "    phi = che_prob(tc_filter,pop)\n",
    "    \n",
    "    return cost_func(arr_rate, phi, pop, s_cachec)\n",
    "\n",
    "def lru_constraint_func(point, arr_rate, pop, kappa, delta, *args, **kwargs):\n",
    "    klru, s_cachec = point\n",
    "    tc_filter = tc_func(klru,pop)\n",
    "    phi = che_prob(tc_filter,pop)\n",
    "    tc_fog = fsolve(lambda t : s_cache_f - np.sum(p01p11(tc_filter,t,pop)), s_cache_f)[0]\n",
    "    hit_fog = p11(tc_filter, tc_fog, pop)/phi\n",
    "    \n",
    "    return constraint_func(arr_rate, phi, s_cachec, kappa, delta, hit_fog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step, to derive an approximate value of $\\phi$, the influence of the cloud cache is overlooked (and $s_{cache,c}$ fixed). $k_{LRU}$ is derived by using Brent's method on $f(t) = \\Delta - \\mathbf E[T]$\n",
    "\n",
    "**Warning:** this step might take a while and raise some warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cachec = 0\n",
    "\n",
    "tc_fog = tc_func(s_cache_f, pop)\n",
    "hit_fog = che_prob(tc_fog, pop)\n",
    "\n",
    "try:\n",
    "    phiB = brentq(lambda x : blind_constraint_func((x, s_cachec), arr_rate, pop, kappa, delta_app, hit_fog), 0, 1)\n",
    "    display(Math(r\"\\phi_{{B}} = {:2.3f},\\; \\mathbf{{E}}[T]={:2.2f}\\,\\mathrm s,\\; \\Pi={:2.2f}\\mathrm \\$/\\mathrm h\".format(phiB, blind_constraint_func((phiB, s_cachec), arr_rate, pop, kappa, delta_app, hit_fog), blind_cost_func((phiB, s_cachec), arr_rate, pop))))\n",
    "except ValueError:\n",
    "    print \"No solution for the blind problem when \",\n",
    "    display(Math(r\"\\lambda={}\".format(arr_rate)))\n",
    "    phiB=0\n",
    "   \n",
    "try:\n",
    "    klfu = brentq(lambda x : lfu_constraint_func((x, s_cachec), arr_rate, pop, kappa, delta_app), 0, R)\n",
    "    display(Math(r\"k_{{LFU}} = {:2.0f},\\; \\mathbf{{E}}[T]={:2.2f}\\,\\mathrm s,\\; \\Pi={:2.2f}\\mathrm \\$/\\mathrm h\".format(klfu, lfu_constraint_func((klfu, s_cachec), arr_rate, pop, kappa, delta_app), lfu_cost_func((klfu, s_cachec), arr_rate, pop))))\n",
    "except ValueError:\n",
    "    print \"No solution for the LFU problem when \",\n",
    "    display(Math(r\"\\lambda={}\".format(arr_rate)))\n",
    "    klfu = 142581\n",
    "\n",
    "try:\n",
    "    klru = brentq(lambda x : lru_constraint_func((x, s_cachec), arr_rate, pop, kappa, delta_app), 1.5e5, 3.5e5)\n",
    "    display(Math(r\"k_{{LRU}} = {:2.0f},\\; \\mathbf{{E}}[T]={:2.2f}\\,\\mathrm s,\\; \\Pi={:2.2f}\\mathrm \\$/\\mathrm h\".format(klru, lru_constraint_func((klru, s_cachec), arr_rate, pop, kappa, delta_app), lru_cost_func((klru, s_cachec), arr_rate, pop))))\n",
    "except ValueError:\n",
    "    print \"No solution for \",\n",
    "    display(Math(r\"\\lambda={}\".format(arr_rate)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use a numerical solver to derive the optimal $s_{cache,c}$ using $k_{LRU}$ as a starting value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openopt import NLP\n",
    "\n",
    "p_blind=NLP(blind_cost_func, [phiB, s_cachec], args=(arr_rate, pop, kappa, delta_app, hit_fog), c=blind_constraint_func, lb=[0,1], ub=[1,R])\n",
    "opt_res_blind = p_blind.solve(\"mma\")\n",
    "p_lfu=NLP(lfu_cost_func, [klfu, s_cachec], args=(arr_rate, pop, kappa, delta_app), c=lfu_constraint_func, lb=[1,1], ub=[R,R])\n",
    "opt_res_lfu = p_lfu.solve(\"mma\")\n",
    "p_lru=NLP(lru_cost_func, [klru, s_cachec], args=(arr_rate, pop, kappa, delta_app), c=lru_constraint_func, lb=[1,1], ub=[R,R])\n",
    "opt_res_lru = p_lru.solve(\"mma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phiB,s_cachec_blind = opt_res_blind.xf\n",
    "display(Math(r\"\\phi_{{B}} = {:2.3f},\\; s_{{cache,c}}={:2.0f},\\; \\mathbf{{E}}[T]={:2.2f}\\,\\mathrm s,\\; \\Pi={:2.2f}\\mathrm \\$/\\mathrm h\".format(phiB, s_cachec_blind, blind_constraint_func((phiB, s_cachec_blind), arr_rate, pop, kappa, delta_app, hit_fog), blind_cost_func((phiB, s_cachec_blind), arr_rate, pop))))\n",
    "\n",
    "klfu,s_cachec_lfu = opt_res_lfu.xf\n",
    "phi_lfu = np.sum(pop[:int(klfu)])\n",
    "display(Math(r\"k_{{LFU}} = {:2.0f},\\; \\phi={:2.3f},\\; s_{{cache,c}}={:2.0f},\\; \\mathbf{{E}}[T]={:2.2f}\\,\\mathrm s,\\; \\Pi={:2.2f}\\mathrm \\$/\\mathrm h\".format(klfu, phi_lfu, s_cachec_lfu, lfu_constraint_func((klfu, s_cachec_lfu), arr_rate, pop, kappa, delta_app), lfu_cost_func((klfu, s_cachec_lfu), arr_rate, pop))))\n",
    "\n",
    "klru,s_cachec_lru = opt_res_lru.xf\n",
    "tc_lru = tc_func(int(klru), pop)\n",
    "hit_lru = che_prob(tc_lru, pop)\n",
    "phi_lru = np.sum(pop*hit_lru)\n",
    "display(Math(r\"k_{{LRU}} = {:2.0f},\\; \\phi={:2.3f},\\; s_{{cache,c}}={:2.0f},\\; \\mathbf{{E}}[T]={:2.2f}\\,\\mathrm s,\\; \\Pi={:2.2f}\\mathrm \\$/\\mathrm h\".format(klru, phi_lru, s_cachec_lru, lru_constraint_func((klru, s_cachec_lru), arr_rate, pop, kappa, delta_app), lru_cost_func((klru, s_cachec_lru), arr_rate, pop))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klru,s_cachec_lru = 1.3e5, 2.9e6\n",
    "tc_lru = tc_func(int(klru), pop)\n",
    "hit_lru = che_prob(tc_lru, pop)\n",
    "phi_lru = np.sum(pop*hit_lru)\n",
    "display(Math(r\"k_{{LRU}} = {:2.0f},\\; \\phi={:2.3f},\\; s_{{cache,c}}={:2.0f},\\; \\mathbf{{E}}[T]={:2.2f}\\,\\mathrm s,\\; \\Pi={:2.2f}\\mathrm \\$/\\mathrm h\".format(klru, phi_lru, s_cachec_lru, lru_constraint_func((klru, s_cachec_lru), arr_rate, pop, kappa, delta_app), lru_cost_func((klru, s_cachec_lru), arr_rate, pop))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From LRU to ABF\n",
    "\n",
    "## Fitting for $N$\n",
    "\n",
    "First, let's derive the coefficients $A$ and $B$ in Proposition V.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_alpha1 (R):\n",
    "    A = 1. + (1. + np.log(np.log(R)) - 2 * np.euler_gamma) / (np.log(R) + np.euler_gamma)\n",
    "    B = 1. / (np.log(R) + np.euler_gamma)\n",
    "    return A,B\n",
    "\n",
    "def hralpha_func(R,alpha): return np.sum(np.arange(1,R+1)**(-alpha))\n",
    "\n",
    "def coef_alpha (R,alpha):\n",
    "    hralpha = hralpha_func(R,alpha)\n",
    "    A = R**(1.0/alpha) / ((1.0-alpha) * hralpha)\n",
    "    B = - gamma(-1.0/alpha) / (alpha**2 * hralpha**(1.0/alpha))\n",
    "    return A,B\n",
    "\n",
    "A,B =  coef_alpha1(R) if alpha==1.0 else coef_alpha(R,alpha)\n",
    "\n",
    "display(Math(r\"A={:2.3f},\\, B={:2.3f}\".format(A,B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From $k_{LRU}$ to $\\widehat{k_1}$\n",
    "\n",
    "Using $\\tilde{N}=k_{LRU}$ in Prop. V.1 gives: $k_{LRU} = \\frac{1}{\\widehat{k_1}} \\sum_{\\widehat{k_1} \\leq k < 2\\widehat{k_1}} f(k)$\n",
    "\n",
    "Let's inverse this equation to find $\\widehat{k_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(k):\n",
    "    if alpha==1.0:\n",
    "        return A*k-B*k*np.log(k)\n",
    "    else:\n",
    "        return A*k-B*k**(1.0/alpha)\n",
    "\n",
    "def ntilde_func(k):\n",
    "    return 1.0 / k * np.sum(f(np.arange(k,2*k)))\n",
    "\n",
    "def k1_func(n): return fsolve(lambda k : n - ntilde_func(k),n)[0]\n",
    "\n",
    "k1 = k1_func(klru)\n",
    "\n",
    "display(Math(r\"\\widehat{{k_1}}={:2.0f}\".format(k1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From $\\widehat{k_1}$ to $n_a$\n",
    "\n",
    "Now, by definition of $\\widehat{k_1}$ (proposition V.3), $n_a = f(\\widehat{k_1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na = f(k1)\n",
    "\n",
    "display(Math(\"n_a={}\".format(int(na))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the memory usage\n",
    "\n",
    "Finally, let's compare the respective memory usage of the LRU and the ABF under the given parameters\n",
    "\n",
    "## LRU filter\n",
    " \n",
    "First, let's compute the minimal pointer size $s_p = \\lceil \\log_2 k_{LRU} \\rceil$ and derive $m_{LRU} = 3k_{LRU} s_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_size = np.ceil(np.log2(klru))\n",
    "#print(\"Pointer size: \", end=None)\n",
    "display(Math(r\"s_p = {:2.0f}\\;\\mathrm{{bits}}\".format(pointer_size)))\n",
    "\n",
    "m_lru = pointer_size*3*klru\n",
    "#print(\"Memory usage:\", end=None)\n",
    "display(Math(r\"m_{{LRU}} = {:2.0f}\\;\\mathrm{{bits}}\".format(m_lru)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABF filter\n",
    "\n",
    "First, we must input the desired false-positive rate $f_p$ in the `f_p` variable.\n",
    "\n",
    "We can then compute $n_h$ the number of necessary hash-functions and the corresponding memory $m_{ABF}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 0.01\n",
    "\n",
    "\n",
    "def nh_func(fp): return np.ceil(-np.log2(1-np.sqrt(1-fp)))\n",
    "nh = nh_func(fp)\n",
    "display(Math(\"n_h = {:2.0f}\".format(nh)))\n",
    "\n",
    "def m_abf_func(na, nh): return np.ceil(2*na*nh/np.log(2))\n",
    "m_abf = m_abf_func(na,nh)\n",
    "display(Math(\"m_{{ABF}} = {:2.0f}\".format(m_abf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRU - ABF comparison -- ABF implementability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r\"\\frac{{m_{{LRU}}}}{{m_{{ABf}}}} = {:2.2f}\".format(m_lru/m_abf)))\n",
    "\n",
    "limit = 2**21\n",
    "if m_abf/2 > limit:\n",
    "    print(\"ABF is too big for the Xilinx card's BRAM\")\n",
    "else:\n",
    "     print(\"ABF is deployable on the Xilinx card's BRAM\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
